# app_agent.py

"""
app_agent.py

Streamlit application entry point for the I-CAN Agent. Imports the agent pipeline,
allows users to initialize with sample data, ask natural-language questions, and
receive responses generated by an autonomous Agent.
"""

import streamlit as st

# Application configuration constants
from config.settings import MODEL_NAME, TEMPERATURE, CHUNK_SIZE, CHUNK_OVERLAP

# Import agent initializer
from retrieval.agent_pipeline import initialize_agent_pipeline

# Document wrapper for text chunks
from langchain.docstore.document import Document


def main() -> None:
    """
    Launches the Streamlit UI, handles initialization of the agent pipeline and
    processes user queries through the conversational Agent.
    """
    st.title("I-CAN Agent: IISc Conversational Academic Navigator")

    # Button to load sample documents and initialize the Agent
    if st.button("Run Test with Sample Data"):
        sample_texts = [
            "Streamlit enables rapid creation of interactive web UIs for ML and data science.",
            "LangChain offers modular building blocks (prompts, chains, agents) for LLM apps.",
            "Retrieval-Augmented Generation (RAG) merges vector retrieval with generative LLMs.",
            "Adjustable CHUNK_SIZE and CHUNK_OVERLAP let you tune retrieval granularity.",
            "Dr. Ratikanta Behera is Assistant Professor, Computational & Data Sciences, IISc Bangalore."
        ]
        docs = [Document(page_content=text) for text in sample_texts]

        # Initialize the Agent and FAISS store, then save to session state
        agent, vs = initialize_agent_pipeline(docs)
        st.session_state.agent = agent
        st.session_state.vs = vs

        st.success(f"Agent initialized with {len(docs)} documents.")

    # Once the Agent is ready, allow QA interactions
    if "agent" in st.session_state:
        st.subheader("Ask a question")
        user_query = st.text_input("Your question:")

        if st.button("Ask") and user_query:
            # Agent decides when to call the retrieval tool and returns an answer
            answer = st.session_state.agent.run(user_query)
            st.markdown(f"**Answer:** {answer}")

    # Sidebar shows current configuration for transparency
    with st.sidebar:
        st.write("**Configuration**")
        st.write(f"Model: {MODEL_NAME}")
        st.write(f"Temperature: {TEMPERATURE}")
        st.write(f"Chunk size: {CHUNK_SIZE}")
        st.write(f"Chunk overlap: {CHUNK_OVERLAP}")


if __name__ == "__main__":

    main()
